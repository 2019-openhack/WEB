{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Thu Jun 27 18:55:35 2019\n",
    "\n",
    "@author: JM\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import re\n",
    "import nltk\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize \n",
    "from tkinter.filedialog import askopenfilename \n",
    "from pdfminer.pdfdocument import PDFDocument\n",
    "from pdfminer.pdfparser import PDFParser\n",
    "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter,resolve1\n",
    "from pdfminer.pdfdevice import PDFDevice, TagExtractor\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "from pdfminer.converter import XMLConverter, HTMLConverter, TextConverter\n",
    "from pdfminer.cmapdb import CMapDB\n",
    "from pdfminer.layout import LAParams\n",
    "from pdfminer.image import ImageWriter\n",
    "\n",
    "\n",
    "class preprocessing:\n",
    "    def __init__(self, input_path, output_path=None):\n",
    "        self.input_path = input_path\n",
    "        self.output_path = output_path\n",
    "\n",
    "    def isExistFile(self):\n",
    "        file_name = self.output_path.split('/')[-1]\n",
    "\n",
    "        for i in os.listdir(\".\"):\n",
    "            if file_name == i:\n",
    "                return True\n",
    "\n",
    "        return False\n",
    "\n",
    "    def pdf2txt(self):\n",
    "        '''\n",
    "        input_path : str, PDF File\n",
    "\n",
    "        =============================\n",
    "\n",
    "        return : str, text File path\n",
    "        '''\n",
    "\n",
    "        # input\n",
    "        password=''\n",
    "        pagenos=set()\n",
    "        maxpages=0\n",
    "\n",
    "        # output\n",
    "        imagewriter = None\n",
    "        rotation = 0\n",
    "        codec = 'UTF-8'\n",
    "        pageno = 1\n",
    "        scale = 1\n",
    "        caching = True\n",
    "        showpageno = True\n",
    "        laparams = LAParams()\n",
    "\n",
    "        infp = open(self.input_path,\"rb\")\n",
    "        \n",
    "        if self.output_path == None:\n",
    "            self.output_path = self.input_path[:-4]+'_trans.txt'\n",
    "            outfp = open(self.output_path,\"w\",encoding='UTF8')\n",
    "        else:\n",
    "            outfp = open(self.output_path,\"w\",encoding='UTF8')\n",
    "            \n",
    "            \n",
    "        #page total num\n",
    "        parser = PDFParser(infp)\n",
    "        document = PDFDocument(parser)\n",
    "        page_total_num = resolve1(document.catalog['Pages'])['Count']\n",
    "\n",
    "        #\n",
    "        rsrcmgr = PDFResourceManager(caching=caching)\n",
    "\n",
    "        # pdf -> text converter\n",
    "        device = TextConverter(rsrcmgr,\n",
    "                               outfp,\n",
    "                               codec=codec,\n",
    "                               laparams=laparams, \n",
    "                               imagewriter=imagewriter)\n",
    "\n",
    "        # pdf -> text interpreter\n",
    "        interpreter = PDFPageInterpreter(rsrcmgr,device)\n",
    "\n",
    "        # pdf -> text start\n",
    "        with tqdm(total=page_total_num) as pbar:\n",
    "            for page in PDFPage.get_pages(infp,\n",
    "                                          pagenos,\n",
    "                                          maxpages,\n",
    "                                          password=password,\n",
    "                                          caching=caching,\n",
    "                                          check_extractable=True):\n",
    "\n",
    "                page.rotate = (page.rotate+rotation) % 360     \n",
    "                interpreter.process_page(page)\n",
    "\n",
    "                pbar.update(1)\n",
    "\n",
    "        print('[INFO] pdf -> text')\n",
    "\n",
    "        outfp.close()\n",
    "        infp.close()\n",
    "    \n",
    "    def clean_text(self):\n",
    "        '''\n",
    "        path : str, text File Path\n",
    "\n",
    "\n",
    "        ===========================\n",
    "\n",
    "        return : list, sentences\n",
    "        '''\n",
    "\n",
    "        f = open(self.output_path,\"rb\")\n",
    "        line_list = []\n",
    "\n",
    "        while True:\n",
    "            line = f.readline()\n",
    "            line_list.append(line)\n",
    "            if not line: break\n",
    "\n",
    "        f.close()\n",
    "\n",
    "        # remove nextline\n",
    "        word = b\" \".join(line_list).split()\n",
    "        sentences = b\" \".join(word)\n",
    "\n",
    "\n",
    "        # remove ASCII\n",
    "        # define pattern \n",
    "        pattern = re.compile(b\"[\\x80-\\xff]\")\n",
    "        sentences = re.sub(pattern,b\"\",sentences)\n",
    "\n",
    "        sentences = sentences.split(b\". \")\n",
    "\n",
    "        f = open(self.output_path,\"wb\")\n",
    "\n",
    "        for sentence in sentences:\n",
    "            sentence = sentence.replace(b\"- \",b'')\n",
    "            sentence = sentence.replace(b\"-\",b'')\n",
    "            #cleaned_txt.append(sentence)\n",
    "            f.write(sentence + b'. ')\n",
    "\n",
    "        f.close()\n",
    "        \n",
    "        print('[INFO] clean text file')\n",
    "        \n",
    "    def word_Frequency(self):\n",
    "        f = open(self.output_path,\"r\")\n",
    "        \n",
    "        text = f.readline()\n",
    "        \n",
    "        # 단어의 빈도수\n",
    "        shortword = re.compile(r'\\W*\\b\\w{1,2}\\b')\n",
    "        text = shortword.sub('', text)\n",
    "        \n",
    "        stop_words = set(stopwords.words('english')) \n",
    "        word_tokens = word_tokenize(text)\n",
    "        \n",
    "        result = [] \n",
    "        \n",
    "        # 불용어 제거\n",
    "        for w in word_tokens: \n",
    "            if w not in stop_words: \n",
    "                parsing = re.sub('[-=+,#/\\?:^$.@*\\\"※~&%}{ㆍ!』\\\\‘|\\(\\)\\[\\]\\<\\>`\\'…》]', '', w)\n",
    "                \n",
    "                if parsing and parsing.isdigit() == False and len(parsing) > 2:\n",
    "                    result.append(w)  \n",
    "\n",
    "        cnt = Counter(result)\n",
    "        \n",
    "        print('[INFO] generation word frequency')\n",
    "        \n",
    "        return cnt\n",
    "    \n",
    "'''    \n",
    "input_path ='C:/Users/JM/Desktop/MCNN.pdf'\n",
    "\n",
    "model = preprocessing(input_path)\n",
    "\n",
    "model.pdf2txt()\n",
    "model.clean_text()\n",
    "model.word_Frequency()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py35",
   "language": "python",
   "name": "py35"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
