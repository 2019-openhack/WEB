{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:02<00:00,  3.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] pdf -> text\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 31/31 [00:06<00:00,  5.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] pdf -> text\n",
      "[INFO] clean text file\n",
      "[INFO] clean text file\n",
      "[INFO] generation word frequency\n",
      "[INFO] generation word frequency\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Thu Jun 27 18:55:35 2019\n",
    "\n",
    "@author: JM\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import re\n",
    "import nltk\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize \n",
    "from tkinter.filedialog import askopenfilename \n",
    "from pdfminer.pdfdocument import PDFDocument\n",
    "from pdfminer.pdfparser import PDFParser\n",
    "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter,resolve1\n",
    "from pdfminer.pdfdevice import PDFDevice, TagExtractor\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "from pdfminer.converter import XMLConverter, HTMLConverter, TextConverter\n",
    "from pdfminer.cmapdb import CMapDB\n",
    "from pdfminer.layout import LAParams\n",
    "from pdfminer.image import ImageWriter\n",
    "\n",
    "\n",
    "class preprocessing:\n",
    "    def __init__(self, input_path, output_path=None):\n",
    "        self.input_path = input_path\n",
    "        self.output_path = output_path\n",
    "\n",
    "    def isExistFile(self):\n",
    "        file_name = self.output_path.split('/')[-1]\n",
    "\n",
    "        for i in os.listdir(\".\"):\n",
    "            if file_name == i:\n",
    "                return True\n",
    "\n",
    "        return False\n",
    "\n",
    "    def pdf2txt(self):\n",
    "        '''\n",
    "        input_path : str, PDF File\n",
    "\n",
    "        =============================\n",
    "\n",
    "        return : str, text File path\n",
    "        '''\n",
    "\n",
    "        # input\n",
    "        password=''\n",
    "        pagenos=set()\n",
    "        maxpages=0\n",
    "\n",
    "        # output\n",
    "        imagewriter = None\n",
    "        rotation = 0\n",
    "        codec = 'UTF-8'\n",
    "        pageno = 1\n",
    "        scale = 1\n",
    "        caching = True\n",
    "        showpageno = True\n",
    "        laparams = LAParams()\n",
    "\n",
    "        infp = open(self.input_path,\"rb\")\n",
    "        \n",
    "        if self.output_path == None:\n",
    "            self.output_path = self.input_path[:-4]+'_trans.txt'\n",
    "            outfp = open(self.output_path,\"w\",encoding='UTF8')\n",
    "        else:\n",
    "            outfp = open(self.output_path,\"w\",encoding='UTF8')\n",
    "            \n",
    "            \n",
    "        #page total num\n",
    "        parser = PDFParser(infp)\n",
    "        document = PDFDocument(parser)\n",
    "        page_total_num = resolve1(document.catalog['Pages'])['Count']\n",
    "\n",
    "        #\n",
    "        rsrcmgr = PDFResourceManager(caching=caching)\n",
    "\n",
    "        # pdf -> text converter\n",
    "        device = TextConverter(rsrcmgr,\n",
    "                               outfp,\n",
    "                               codec=codec,\n",
    "                               laparams=laparams, \n",
    "                               imagewriter=imagewriter)\n",
    "\n",
    "        # pdf -> text interpreter\n",
    "        interpreter = PDFPageInterpreter(rsrcmgr,device)\n",
    "\n",
    "        # pdf -> text start\n",
    "        with tqdm(total=page_total_num) as pbar:\n",
    "            for page in PDFPage.get_pages(infp,\n",
    "                                          pagenos,\n",
    "                                          maxpages,\n",
    "                                          password=password,\n",
    "                                          caching=caching,\n",
    "                                          check_extractable=True):\n",
    "\n",
    "                page.rotate = (page.rotate+rotation) % 360     \n",
    "                interpreter.process_page(page)\n",
    "\n",
    "                pbar.update(1)\n",
    "\n",
    "        print('[INFO] pdf -> text')\n",
    "\n",
    "        outfp.close()\n",
    "        infp.close()\n",
    "    \n",
    "    def clean_text(self):\n",
    "        '''\n",
    "        path : str, text File Path\n",
    "\n",
    "\n",
    "        ===========================\n",
    "\n",
    "        return : list, sentences\n",
    "        '''\n",
    "\n",
    "        f = open(self.output_path,\"rb\")\n",
    "        line_list = []\n",
    "\n",
    "        while True:\n",
    "            line = f.readline()\n",
    "            line_list.append(line)\n",
    "            if not line: break\n",
    "\n",
    "        f.close()\n",
    "\n",
    "        # remove nextline\n",
    "        word = b\" \".join(line_list).split()\n",
    "        sentences = b\" \".join(word)\n",
    "\n",
    "\n",
    "        # remove ASCII\n",
    "        # define pattern \n",
    "        pattern = re.compile(b\"[\\x80-\\xff]\")\n",
    "        sentences = re.sub(pattern,b\"\",sentences)\n",
    "\n",
    "        sentences = sentences.split(b\". \")\n",
    "\n",
    "        f = open(self.output_path,\"wb\")\n",
    "\n",
    "        for sentence in sentences:\n",
    "            sentence = sentence.replace(b\"- \",b'')\n",
    "            sentence = sentence.replace(b\"-\",b'')\n",
    "            #cleaned_txt.append(sentence)\n",
    "            f.write(sentence + b'. ')\n",
    "\n",
    "        f.close()\n",
    "        \n",
    "        print('[INFO] clean text file')\n",
    "        \n",
    "    def example\n",
    "        \n",
    "    def word_Frequency(self):\n",
    "        f = open(self.output_path,\"r\")\n",
    "\n",
    "        text = f.readline()\n",
    "\n",
    "        # 단어의 빈도수\n",
    "        shortword = re.compile(r'\\W*\\b\\w{1,2}\\b')\n",
    "        text = shortword.sub('', text)\n",
    "\n",
    "        stop_words = set(stopwords.words('english')) \n",
    "        word_tokens = word_tokenize(text)\n",
    "\n",
    "        result = [] \n",
    "\n",
    "        # 불용어 제거\n",
    "        for w in word_tokens: \n",
    "            if w not in stop_words: \n",
    "                parsing = ''.join([i for i in w if not i.isdigit()]) \n",
    "                parsing = re.sub('[-=+,#/\\?:^$.@*\\\"※~&%}{ㆍ!』\\\\‘|\\(\\)\\[\\]\\<\\>`\\'…》]', '', parsing)\n",
    "\n",
    "\n",
    "                if parsing and parsing.isdigit() == False and len(parsing) > 2:\n",
    "                    result.append(w)  \n",
    "\n",
    "        cnt = Counter(result)\n",
    "        \n",
    "        print('[INFO] generation word frequency')\n",
    "        \n",
    "        return cnt\n",
    "    \n",
    "\n",
    "\n",
    "input_path1 ='C:/Users/JM/Desktop/MCNN.pdf'\n",
    "input_path2 ='C:/Users/JM/Desktop/YOLO.pdf'\n",
    "\n",
    "pdf1 = preprocessing(input_path1)\n",
    "pdf2 = preprocessing(input_path2)\n",
    "\n",
    "pdf1.pdf2txt()\n",
    "pdf2.pdf2txt()\n",
    "\n",
    "pdf1.clean_text()\n",
    "pdf2.clean_text()\n",
    "\n",
    "cnt1 = pdf1.word_Frequency()\n",
    "cnt2 = pdf2.word_Frequency()\n",
    "\n",
    "cnt = cnt1 + cnt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'adopted': 1,\n",
       "         'connected': 14,\n",
       "         'support': 1,\n",
       "         'generic': 1,\n",
       "         'vision': 1,\n",
       "         'methods': 25,\n",
       "         'composed': 1,\n",
       "         'scene': 9,\n",
       "         'shanghaitech.edu': 1,\n",
       "         'layer': 50,\n",
       "         'agglomerative': 1,\n",
       "         'Acknowledgement': 1,\n",
       "         'distributed': 2,\n",
       "         'derive': 1,\n",
       "         'correctly': 1,\n",
       "         'remaining': 2,\n",
       "         'Many': 1,\n",
       "         'Transfer': 2,\n",
       "         'sanctuaries': 1,\n",
       "         'provides': 1,\n",
       "         'embedding': 1,\n",
       "         'Shapebased': 1,\n",
       "         'Class|': 2,\n",
       "         'score': 23,\n",
       "         'single': 15,\n",
       "         'trafc': 2,\n",
       "         'evaluation': 5,\n",
       "         'available': 1,\n",
       "         'Networks': 2,\n",
       "         'Unfortunately': 3,\n",
       "         'Training': 15,\n",
       "         'features': 22,\n",
       "         'propose': 4,\n",
       "         'Average': 2,\n",
       "         'uses': 4,\n",
       "         'kernels': 6,\n",
       "         'group': 4,\n",
       "         'Both': 1,\n",
       "         'coord': 1,\n",
       "         'piecewise': 1,\n",
       "         'layers': 15,\n",
       "         'MCNNCCR': 2,\n",
       "         'component': 4,\n",
       "         'They': 1,\n",
       "         'meaningful': 1,\n",
       "         'know': 3,\n",
       "         'actual': 1,\n",
       "         'MultiColumn': 1,\n",
       "         'heads': 15,\n",
       "         'Digital': 1,\n",
       "         'computational': 2,\n",
       "         'applicability': 1,\n",
       "         'last': 12,\n",
       "         'consistent': 1,\n",
       "         'Five': 1,\n",
       "         'without': 4,\n",
       "         'domain': 22,\n",
       "         '2007test': 4,\n",
       "         'pattern': 1,\n",
       "         'seen': 1,\n",
       "         'learned': 9,\n",
       "         'advanced/effective': 1,\n",
       "         'map': 42,\n",
       "         'invariant': 1,\n",
       "         'Sence3': 1,\n",
       "         'consecutive': 1,\n",
       "         'unaffected': 1,\n",
       "         'ICCV': 4,\n",
       "         'area': 3,\n",
       "         'ability': 1,\n",
       "         'Computing': 1,\n",
       "         'Conventional': 1,\n",
       "         'Due': 1,\n",
       "         'objects': 3,\n",
       "         'public': 2,\n",
       "         'ICPR': 1,\n",
       "         'ways': 1,\n",
       "         'Counting': 6,\n",
       "         'see': 5,\n",
       "         'BMVC': 2,\n",
       "         'victims': 1,\n",
       "         'learning': 15,\n",
       "         'jams': 1,\n",
       "         'averagepooling': 2,\n",
       "         'followed': 2,\n",
       "         'place': 1,\n",
       "         'unit': 1,\n",
       "         'abnormal': 1,\n",
       "         'according': 3,\n",
       "         'centers': 3,\n",
       "         'Rectied': 1,\n",
       "         'When': 1,\n",
       "         'hence': 4,\n",
       "         'knowledge': 2,\n",
       "         'Viola': 1,\n",
       "         'applied': 2,\n",
       "         'ensures': 2,\n",
       "         'advantage': 1,\n",
       "         'affects': 1,\n",
       "         'outperforms': 5,\n",
       "         'fast': 2,\n",
       "         'multi': 2,\n",
       "         'neuron': 1,\n",
       "         'columns': 4,\n",
       "         'achieved': 2,\n",
       "         'say': 1,\n",
       "         'Fast': 13,\n",
       "         'take': 1,\n",
       "         'Shenghua': 1,\n",
       "         'cluster': 1,\n",
       "         'metropolitan': 2,\n",
       "         'Therefore': 5,\n",
       "         'boosted': 1,\n",
       "         'integral': 1,\n",
       "         'object+how': 1,\n",
       "         'appearance': 2,\n",
       "         'detectionbased': 4,\n",
       "         'reality': 1,\n",
       "         'competitive': 1,\n",
       "         'Comparing': 4,\n",
       "         'COMPUT': 1,\n",
       "         'Vanhoucke': 1,\n",
       "         'present': 1,\n",
       "         'found': 2,\n",
       "         'exposure': 2,\n",
       "         'fall': 1,\n",
       "         'Original': 1,\n",
       "         'human': 1,\n",
       "         'scales': 4,\n",
       "         'Venkatesh': 2,\n",
       "         'important': 1,\n",
       "         'end': 2,\n",
       "         'need': 5,\n",
       "         'among': 1,\n",
       "         'dense': 7,\n",
       "         'similar': 5,\n",
       "         'robustness': 1,\n",
       "         'zhangyy2': 1,\n",
       "         'Learning': 2,\n",
       "         'Label': 1,\n",
       "         'IOU': 12,\n",
       "         'faces': 1,\n",
       "         'MCNN': 48,\n",
       "         'International': 2,\n",
       "         'Donahue': 1,\n",
       "         'sparse': 2,\n",
       "         'paper': 6,\n",
       "         'linear': 7,\n",
       "         'mid': 1,\n",
       "         'Teh': 1,\n",
       "         'meter': 2,\n",
       "         'Caffe': 4,\n",
       "         'predicting': 2,\n",
       "         'whole': 6,\n",
       "         'reduces': 1,\n",
       "         'Fourier': 1,\n",
       "         'CNNs': 15,\n",
       "         'Input': 1,\n",
       "         'training': 34,\n",
       "         'rstly': 2,\n",
       "         'Multisource': 1,\n",
       "         'batchbased': 1,\n",
       "         'maintaining': 1,\n",
       "         'category': 2,\n",
       "         'Model': 1,\n",
       "         'provided': 3,\n",
       "         'handcraft': 1,\n",
       "         'greatly': 2,\n",
       "         'decomposition': 1,\n",
       "         'Laptev': 1,\n",
       "         'suitable': 2,\n",
       "         'Wang': 3,\n",
       "         'adequately': 1,\n",
       "         'daunting': 1,\n",
       "         'comparing': 2,\n",
       "         'stack': 1,\n",
       "         'cropped': 1,\n",
       "         'Except': 1,\n",
       "         'favor': 1,\n",
       "         'Estimating': 1,\n",
       "         'Conference': 1,\n",
       "         'plots': 1,\n",
       "         'Marked': 1,\n",
       "         'immediate': 1,\n",
       "         'backpropagation': 1,\n",
       "         'clustered': 1,\n",
       "         'typically': 3,\n",
       "         'estimates': 3,\n",
       "         'adaptation': 2,\n",
       "         'Accurately': 1,\n",
       "         'precision': 4,\n",
       "         'may': 3,\n",
       "         'Darrell': 2,\n",
       "         'per': 2,\n",
       "         'somewhat': 1,\n",
       "         'Trade': 2,\n",
       "         'stochastic': 1,\n",
       "         'recognition': 3,\n",
       "         'global': 1,\n",
       "         'extremely': 3,\n",
       "         'downsample': 1,\n",
       "         'means': 3,\n",
       "         'Xiang': 2,\n",
       "         'proposal': 6,\n",
       "         'within': 1,\n",
       "         'predictor': 17,\n",
       "         'netuning': 8,\n",
       "         'Local': 1,\n",
       "         'typical': 2,\n",
       "         'well': 5,\n",
       "         'Density': 3,\n",
       "         'author': 1,\n",
       "         'Nguyen': 1,\n",
       "         'video': 6,\n",
       "         'dis': 1,\n",
       "         'predicti': 1,\n",
       "         'demonstrates': 2,\n",
       "         'convolutional': 21,\n",
       "         'preserved': 2,\n",
       "         'Mean': 3,\n",
       "         'tracker': 1,\n",
       "         'sumsquared': 7,\n",
       "         'Karayev': 1,\n",
       "         'considered': 4,\n",
       "         'head': 15,\n",
       "         'probabilities': 3,\n",
       "         'resort': 1,\n",
       "         'momentum.0005': 2,\n",
       "         'collect': 1,\n",
       "         'Processing': 3,\n",
       "         'China': 1,\n",
       "         'far': 3,\n",
       "         'get': 1,\n",
       "         'moving': 3,\n",
       "         'revise': 1,\n",
       "         'concatenated': 1,\n",
       "         'extensively': 1,\n",
       "         'total': 9,\n",
       "         'examples': 2,\n",
       "         'difcult': 3,\n",
       "         'training/testing': 1,\n",
       "         'extensive': 1,\n",
       "         'containing': 3,\n",
       "         'Titan': 2,\n",
       "         'absolute': 2,\n",
       "         'rallies': 1,\n",
       "         'interest': 2,\n",
       "         'satisfy': 1,\n",
       "         'train': 4,\n",
       "         'ground_truth': 2,\n",
       "         'named': 3,\n",
       "         'vary': 1,\n",
       "         'curate': 1,\n",
       "         'motion': 4,\n",
       "         'Contributions': 2,\n",
       "         'plane': 3,\n",
       "         'determine': 2,\n",
       "         'Chan': 2,\n",
       "         'average': 12,\n",
       "         'parallelized': 1,\n",
       "         'Liang': 1,\n",
       "         'Each': 1,\n",
       "         'Binary': 1,\n",
       "         'Chen': 3,\n",
       "         'Schmidhuber': 1,\n",
       "         'Soomro': 1,\n",
       "         'eve': 1,\n",
       "         'System': 2,\n",
       "         'entry': 1,\n",
       "         'Brostow': 1,\n",
       "         'signicantly': 6,\n",
       "         'attribute': 1,\n",
       "         'Yang': 2,\n",
       "         'suggested': 1,\n",
       "         '59dimensional': 1,\n",
       "         'recall': 2,\n",
       "         'denote': 1,\n",
       "         'keeping': 1,\n",
       "         'veries': 2,\n",
       "         'Images': 1,\n",
       "         'Layer': 4,\n",
       "         'inputs': 2,\n",
       "         'Estimation': 2,\n",
       "         'referred': 1,\n",
       "         'Performance': 1,\n",
       "         'Hence': 4,\n",
       "         'Crossscene': 1,\n",
       "         'inadequate': 1,\n",
       "         'accurately': 8,\n",
       "         'already': 1,\n",
       "         'Groundtruth': 2,\n",
       "         'GPR': 1,\n",
       "         'exiting': 2,\n",
       "         'netuned': 2,\n",
       "         'Following': 1,\n",
       "         'receptive': 6,\n",
       "         'contains': 11,\n",
       "         'Sence2': 1,\n",
       "         'underlying': 1,\n",
       "         'leaky': 4,\n",
       "         'There': 4,\n",
       "         'computed': 1,\n",
       "         'overcome': 1,\n",
       "         'ons': 1,\n",
       "         'best': 2,\n",
       "         'Here': 2,\n",
       "         'streets': 2,\n",
       "         'minima': 1,\n",
       "         'reports': 1,\n",
       "         'fusing': 1,\n",
       "         'pretrained': 6,\n",
       "         'arXiv:1507.08445': 1,\n",
       "         'dramatically': 1,\n",
       "         'supported': 1,\n",
       "         'simply': 3,\n",
       "         'event': 1,\n",
       "         'All': 2,\n",
       "         'activaion': 2,\n",
       "         'selforganizing': 1,\n",
       "         'stampede': 1,\n",
       "         'Sivic': 1,\n",
       "         'Intelligence': 3,\n",
       "         'second': 1,\n",
       "         'annotated': 11,\n",
       "         'privacy': 1,\n",
       "         'respectively': 1,\n",
       "         'preservation': 1,\n",
       "         'overall': 4,\n",
       "         'Face': 1,\n",
       "         'Dean': 1,\n",
       "         'randomly': 3,\n",
       "         'degrades': 1,\n",
       "         'Attribute': 1,\n",
       "         'numbers': 1,\n",
       "         'introduced': 3,\n",
       "         'MESA': 1,\n",
       "         'Girshick': 1,\n",
       "         'height': 12,\n",
       "         'VOC': 15,\n",
       "         'safety': 1,\n",
       "         'detect': 4,\n",
       "         'avoid': 1,\n",
       "         'Total,885,974': 1,\n",
       "         'small': 12,\n",
       "         'namely': 2,\n",
       "         'three': 4,\n",
       "         'learnt': 1,\n",
       "         'aspect': 2,\n",
       "         'fastest': 1,\n",
       "         'Gray': 1,\n",
       "         'traditional': 1,\n",
       "         'rectied': 1,\n",
       "         'videos': 2,\n",
       "         'Struggle': 1,\n",
       "         'replace': 1,\n",
       "         'kind': 1,\n",
       "         'structures': 1,\n",
       "         'literature': 2,\n",
       "         'raw': 1,\n",
       "         'gap': 1,\n",
       "         'epochs': 3,\n",
       "         'Conclusion': 1,\n",
       "         'adopts': 1,\n",
       "         'crowds': 10,\n",
       "         'particularly': 1,\n",
       "         'modify': 1,\n",
       "         'specically': 1,\n",
       "         'truth': 19,\n",
       "         'stateoftheart': 1,\n",
       "         'chosen': 1,\n",
       "         'better': 3,\n",
       "         'increasing': 2,\n",
       "         'aims': 1,\n",
       "         'coordinate': 2,\n",
       "         'Truth': 1,\n",
       "         'reflect': 1,\n",
       "         'nevertheless': 1,\n",
       "         'limited': 3,\n",
       "         'realtime': 5,\n",
       "         'pages': 18,\n",
       "         'Pujiang': 1,\n",
       "         'nets': 1,\n",
       "         'high': 4,\n",
       "         'combination': 1,\n",
       "         'tends': 1,\n",
       "         'Table1': 1,\n",
       "         'empirically': 1,\n",
       "         'prefer': 1,\n",
       "         'release': 1,\n",
       "         'cover': 1,\n",
       "         'Segmentation': 1,\n",
       "         'estimated': 10,\n",
       "         'become': 1,\n",
       "         'sequence': 2,\n",
       "         'Experiments': 1,\n",
       "         'multiply': 1,\n",
       "         'conditional': 4,\n",
       "         'Testing': 1,\n",
       "         'trade': 2,\n",
       "         'good': 5,\n",
       "         'Neocognitron': 1,\n",
       "         'largest': 3,\n",
       "         'helps': 1,\n",
       "         'except': 1,\n",
       "         'sliding': 2,\n",
       "         'gure': 1,\n",
       "         'width': 12,\n",
       "         'obtained': 2,\n",
       "         'Nevertheless': 1,\n",
       "         'Finetune': 2,\n",
       "         'counting': 33,\n",
       "         'success': 2,\n",
       "         'analysis': 2,\n",
       "         'particular': 2,\n",
       "         'employs': 1,\n",
       "         'conditions': 1,\n",
       "         'inspired': 1,\n",
       "         'determines': 1,\n",
       "         'process': 1,\n",
       "         'pooling': 2,\n",
       "         'DPM': 4,\n",
       "         'Linear': 1,\n",
       "         'achieves': 2,\n",
       "         'enough': 1,\n",
       "         'starting': 1,\n",
       "         'MSE': 8,\n",
       "         'participating': 1,\n",
       "         'leverage': 1,\n",
       "         'surveillance': 2,\n",
       "         'events': 1,\n",
       "         'Test': 2,\n",
       "         'etc': 1,\n",
       "         'gives': 5,\n",
       "         'Privacy': 1,\n",
       "         'selected': 1,\n",
       "         'dropout': 4,\n",
       "         'effective': 2,\n",
       "         'readily': 2,\n",
       "         'Tesei': 1,\n",
       "         'across': 3,\n",
       "         'batch': 4,\n",
       "         'Recognition': 1,\n",
       "         'challenging': 5,\n",
       "         'But': 2,\n",
       "         'Program.15PJ1405700': 1,\n",
       "         'congurations': 1,\n",
       "         'reduced': 1,\n",
       "         'augment': 1,\n",
       "         'corresponds': 1,\n",
       "         'assumptions': 1,\n",
       "         'Bansal': 1,\n",
       "         'independently': 2,\n",
       "         'region': 10,\n",
       "         'RCNN': 13,\n",
       "         'caused': 2,\n",
       "         'integrated': 1,\n",
       "         'stand': 1,\n",
       "         'Lotufo': 1,\n",
       "         'soobtained': 1,\n",
       "         'regions': 3,\n",
       "         'adaptive': 3,\n",
       "         'continuous': 1,\n",
       "         'sample': 3,\n",
       "         'preserve': 1,\n",
       "         'almost': 3,\n",
       "         'practice': 1,\n",
       "         'random': 1,\n",
       "         'natural': 3,\n",
       "         'performance': 14,\n",
       "         'develop': 1,\n",
       "         'People': 3,\n",
       "         'drops': 1,\n",
       "         'transfer': 5,\n",
       "         'column': 11,\n",
       "         'comparable': 2,\n",
       "         'error': 29,\n",
       "         'MAE': 10,\n",
       "         'rate': 9,\n",
       "         'transportation': 1,\n",
       "         'UCSD': 8,\n",
       "         'Comparation': 1,\n",
       "         'preserving': 1,\n",
       "         'estimation': 10,\n",
       "         'CVPR': 11,\n",
       "         'altime': 1,\n",
       "         'Unsupervised': 1,\n",
       "         'pipeline': 6,\n",
       "         'implementation': 1,\n",
       "         'compare': 5,\n",
       "         'extract': 1,\n",
       "         'Precision': 3,\n",
       "         'original': 3,\n",
       "         'deviation': 5,\n",
       "         'patch': 2,\n",
       "         'application': 1,\n",
       "         'encoding': 4,\n",
       "         'show': 2,\n",
       "         'SIFT': 2,\n",
       "         'detectionstyle': 1,\n",
       "         'optimized': 2,\n",
       "         'From': 1,\n",
       "         'geometryadaptive': 5,\n",
       "         'document': 1,\n",
       "         'Sumsquarederror': 2,\n",
       "         'impossible': 2,\n",
       "         'multisource': 1,\n",
       "         'year': 1,\n",
       "         'Ave': 2,\n",
       "         '1000class': 3,\n",
       "         'Seibert': 1,\n",
       "         'zero': 4,\n",
       "         'due': 5,\n",
       "         'entirely': 1,\n",
       "         'time': 2,\n",
       "         'situations': 2,\n",
       "         'hubs': 1,\n",
       "         'delta': 1,\n",
       "         'cells': 1,\n",
       "         'Senior': 1,\n",
       "         'Mao': 1,\n",
       "         'lter': 1,\n",
       "         'Part_B': 2,\n",
       "         'weight': 4,\n",
       "         'contain': 2,\n",
       "         'calculated': 1,\n",
       "         'edgelet': 1,\n",
       "         'Convolution': 7,\n",
       "         'tact': 1,\n",
       "         'usually': 4,\n",
       "         'problem': 5,\n",
       "         'Num': 2,\n",
       "         'Desen': 1,\n",
       "         'Crowd': 4,\n",
       "         'eliminate': 1,\n",
       "         'extracting': 1,\n",
       "         'columns.': 1,\n",
       "         'occlusion': 3,\n",
       "         'Tao': 1,\n",
       "         'arbitrary': 10,\n",
       "         'Shah': 2,\n",
       "         'Signal': 1,\n",
       "         'estimating': 3,\n",
       "         'activation': 3,\n",
       "         'resolutions': 1,\n",
       "         'pixel': 5,\n",
       "         'More': 2,\n",
       "         'squared': 1,\n",
       "         'number': 29,\n",
       "         'Belongie': 1,\n",
       "         'fact': 2,\n",
       "         'boosting': 1,\n",
       "         'chensq': 1,\n",
       "         'consequently': 1,\n",
       "         'advantages': 1,\n",
       "         'focusing': 1,\n",
       "         'performence': 2,\n",
       "         'Class': 11,\n",
       "         'Optimization': 1,\n",
       "         'Introduction': 1,\n",
       "         'ridge': 3,\n",
       "         'planning': 1,\n",
       "         'representative': 1,\n",
       "         'refer': 2,\n",
       "         'system': 2,\n",
       "         'compared': 1,\n",
       "         'modeling': 1,\n",
       "         'tracked': 3,\n",
       "         'saturation': 2,\n",
       "         'Only': 2,\n",
       "         'scaling': 2,\n",
       "         'label': 3,\n",
       "         'domains': 1,\n",
       "         'parameterized': 1,\n",
       "         'twice': 1,\n",
       "         'NEURAL': 1,\n",
       "         'measure': 1,\n",
       "         'convention': 1,\n",
       "         'input': 21,\n",
       "         'ROI': 7,\n",
       "         'confidence': 31,\n",
       "         'convolution': 7,\n",
       "         'publication': 1,\n",
       "         'number/density': 1,\n",
       "         'spread': 4,\n",
       "         'classication': 2,\n",
       "         'wavelet': 1,\n",
       "         'LeCun': 1,\n",
       "         'ICASSP': 1,\n",
       "         'local': 5,\n",
       "         'simultaneously': 3,\n",
       "         'Shelhamer': 2,\n",
       "         'entire': 2,\n",
       "         'Fookes': 1,\n",
       "         'appearing': 1,\n",
       "         'Max': 3,\n",
       "         'detecting': 1,\n",
       "         'GPU': 2,\n",
       "         'whose': 8,\n",
       "         'One': 2,\n",
       "         'variety': 1,\n",
       "         'Object': 21,\n",
       "         'extracted': 3,\n",
       "         'Ranzato': 1,\n",
       "         'featurebased': 1,\n",
       "         'page': 1,\n",
       "         'However': 6,\n",
       "         'architecture': 4,\n",
       "         'maps': 22,\n",
       "         'Long': 2,\n",
       "         'representing': 2,\n",
       "         'vector': 2,\n",
       "         'practical': 2,\n",
       "         'Evaluation': 2,\n",
       "         'Graphics': 1,\n",
       "         'class': 31,\n",
       "         'kernel': 7,\n",
       "         'preprint': 3,\n",
       "         'microscopic': 1,\n",
       "         'detections': 1,\n",
       "         'Table': 13,\n",
       "         'Histograms': 1,\n",
       "         'Information': 1,\n",
       "         'Sence5': 1,\n",
       "         'semantic': 2,\n",
       "         'challenges': 2,\n",
       "         'works': 8,\n",
       "         'obj': 3,\n",
       "         'largescale': 2,\n",
       "         'scores': 3,\n",
       "         'matching': 1,\n",
       "         'networks': 8,\n",
       "         'signicant': 1,\n",
       "         'Pretraining': 3,\n",
       "         'Besides': 1,\n",
       "         'Osindero': 1,\n",
       "         'partially': 1,\n",
       "         'naver.com': 2,\n",
       "         'mask': 2,\n",
       "         'environment': 1,\n",
       "         'Their': 1,\n",
       "         'intensities': 1,\n",
       "         'annotations': 2,\n",
       "         'order': 2,\n",
       "         'useful': 2,\n",
       "         'utilize': 1,\n",
       "         'simple': 5,\n",
       "         'trajectories': 1,\n",
       "         'section': 1,\n",
       "         'utilized': 1,\n",
       "         'still': 8,\n",
       "         'point': 2,\n",
       "         'effect': 8,\n",
       "         'trackingbased': 1,\n",
       "         'xed': 1,\n",
       "         'Finetuning': 1,\n",
       "         'Inference': 2,\n",
       "         'clustering': 1,\n",
       "         'capture': 1,\n",
       "         'reported': 1,\n",
       "         'proportional': 2,\n",
       "         'people/head': 2,\n",
       "         'offset': 2,\n",
       "         'rst': 8,\n",
       "         'labelled': 2,\n",
       "         'spatial': 3,\n",
       "         'accepted': 1,\n",
       "         'use': 18,\n",
       "         'based': 20,\n",
       "         'claimed': 1,\n",
       "         'homography': 1,\n",
       "         'generalizability': 3,\n",
       "         'fully': 11,\n",
       "         'deep': 8,\n",
       "         'certain': 3,\n",
       "         'combine': 1,\n",
       "         'busy': 2,\n",
       "         'Kernel': 1,\n",
       "         'augmentation': 1,\n",
       "         'SingleImage': 1,\n",
       "         'Union': 1,\n",
       "         'falls': 1,\n",
       "         'neighboring': 1,\n",
       "         'Related': 1,\n",
       "         'denotes': 1,\n",
       "         'Jones': 1,\n",
       "         'competition': 3,\n",
       "         'indispensable': 1,\n",
       "         'divided': 3,\n",
       "         'mean': 4,\n",
       "         'poisson': 1,\n",
       "         'fps': 1,\n",
       "         'novel': 1,\n",
       "         'stampedes': 1,\n",
       "         'limitation': 1,\n",
       "         'crowding': 1,\n",
       "         'robust': 2,\n",
       "         'Figure': 17,\n",
       "         'information': 8,\n",
       "         'approach': 2,\n",
       "         'neighbors': 3,\n",
       "         'transferred': 3,\n",
       "         'Part_A': 2,\n",
       "         'Automatic': 1,\n",
       "         'University': 1,\n",
       "         'specic': 1,\n",
       "         'Network': 9,\n",
       "         'distortion': 6,\n",
       "         'overlapping': 1,\n",
       "         'localised': 1,\n",
       "         'otherwise': 1,\n",
       "         'position': 1,\n",
       "         'sees': 1,\n",
       "         'details': 1,\n",
       "         'shows': 4,\n",
       "         'higher': 1,\n",
       "         'Ryan': 1,\n",
       "         'yield': 1,\n",
       "         'Process': 1,\n",
       "         'MCNNs': 2,\n",
       "         'associated': 2,\n",
       "         'Representative': 2,\n",
       "         'Motivated': 2,\n",
       "         'Computer': 3,\n",
       "         'convpoolingconvpooling': 1,\n",
       "         'larger': 4,\n",
       "         'GoogLeNet': 6,\n",
       "         'knowing': 1,\n",
       "         'testing': 4,\n",
       "         'locations': 1,\n",
       "         'similarity': 1,\n",
       "         'estimate': 17,\n",
       "         'pretraining': 6,\n",
       "         'square': 2,\n",
       "         'arXiv:1411.4038': 1,\n",
       "         'geometric': 1,\n",
       "         'decay': 2,\n",
       "         'baseline': 1,\n",
       "         'pretrain': 4,\n",
       "         'variance': 1,\n",
       "         'Detection': 21,\n",
       "         'Good': 1,\n",
       "         'sizes': 17,\n",
       "         'Showing': 1,\n",
       "         'initialization': 1,\n",
       "         'Shanghai': 5,\n",
       "         'Gao': 1,\n",
       "         'MDNNs': 3,\n",
       "         'samples': 9,\n",
       "         'KLT': 1,\n",
       "         'Ciresan': 1,\n",
       "         'Kong': 1,\n",
       "         'preprocessed': 1,\n",
       "         'Sence4': 1,\n",
       "         'highest': 2,\n",
       "         'improves': 1,\n",
       "         'steps': 1,\n",
       "         'mapping': 2,\n",
       "         'segment': 1,\n",
       "         'Fukushima': 1,\n",
       "         'How': 6,\n",
       "         'Cipolla': 1,\n",
       "         'occlusions': 1,\n",
       "         'therefore': 1,\n",
       "         'captured': 1,\n",
       "         'characteristics': 1,\n",
       "         'Without': 1,\n",
       "         'epoch': 8,\n",
       "         '5fold': 1,\n",
       "         'monitoring': 3,\n",
       "         'arrive': 1,\n",
       "         'computer': 1,\n",
       "         'descent': 1,\n",
       "         'Nevatia': 2,\n",
       "         'This': 11,\n",
       "         'Foreground': 1,\n",
       "         'settings': 2,\n",
       "         'manually': 1,\n",
       "         'main': 1,\n",
       "         'large': 9,\n",
       "         'comparison': 3,\n",
       "         'Image': 4,\n",
       "         'compute': 1,\n",
       "         'via': 7,\n",
       "         'increasingly': 1,\n",
       "         'normalize': 1,\n",
       "         'difference': 2,\n",
       "         'demonstrate': 2,\n",
       "         'Specically': 1,\n",
       "         'individuals': 2,\n",
       "         'Part': 34,\n",
       "         'directly': 4,\n",
       "         'Arguably': 1,\n",
       "         'loss': 22,\n",
       "         'correspond': 2,\n",
       "         'ratios': 2,\n",
       "         'max': 1,\n",
       "         'parttemplate': 1,\n",
       "         'errors': 1,\n",
       "         'sources': 2,\n",
       "         'Idrees': 5,\n",
       "         'mining': 1,\n",
       "         'ReLU': 1,\n",
       "         'future': 1,\n",
       "         'evaluate': 5,\n",
       "         'Roughly': 1,\n",
       "         'arXiv:1408.5093': 1,\n",
       "         'units': 1,\n",
       "         'method': 25,\n",
       "         'iii': 1,\n",
       "         'labeled': 6,\n",
       "         'NSFC': 1,\n",
       "         'inaccurate': 1,\n",
       "         'call': 1,\n",
       "         'metric': 4,\n",
       "         'presented': 1,\n",
       "         'using': 10,\n",
       "         'algorithm': 2,\n",
       "         'Number': 2,\n",
       "         'wildlife': 1,\n",
       "         'also': 17,\n",
       "         'axis': 1,\n",
       "         'locallyconsistent': 1,\n",
       "         'set': 7,\n",
       "         'happens': 1,\n",
       "         'geometry': 3,\n",
       "         'complexity': 2,\n",
       "         'DOI.1109/CVPR.2016': 1,\n",
       "         'boxes': 6,\n",
       "         'choice': 1,\n",
       "         'Ground': 1,\n",
       "         'people': 23,\n",
       "         'conduct': 3,\n",
       "         'Saleemi': 1,\n",
       "         'eld': 1,\n",
       "         'experiments': 3,\n",
       "         'pedestrian': 2,\n",
       "         'differences': 1,\n",
       "         'ImageNet': 6,\n",
       "         'easy': 1,\n",
       "         'Journal': 1,\n",
       "         'Furthermore': 1,\n",
       "         'lters': 17,\n",
       "         'sequences': 3,\n",
       "         'Secondly': 1,\n",
       "         'Huang': 1,\n",
       "         'different': 35,\n",
       "         'scale': 3,\n",
       "         'Techniques': 1,\n",
       "         'BpBgt': 4,\n",
       "         'proposed': 16,\n",
       "         'utilizing': 2,\n",
       "         'around': 5,\n",
       "         'existing': 11,\n",
       "         'Better': 1,\n",
       "         'instance': 3,\n",
       "         'Sridharan': 1,\n",
       "         'Hinton': 1,\n",
       "         'Feature': 1,\n",
       "         'occluded': 1,\n",
       "         'relationship': 1,\n",
       "         'developed': 1,\n",
       "         'balancing': 2,\n",
       "         'Look': 2,\n",
       "         'Interesting': 1,\n",
       "         'predicted': 2,\n",
       "         'machine': 1,\n",
       "         'Shanghaitech': 16,\n",
       "         'quality': 1,\n",
       "         'elds': 5,\n",
       "         'Gaussian': 6,\n",
       "         'Citeseer': 1,\n",
       "         'Regazzoni': 1,\n",
       "         'Loy': 2,\n",
       "         'points': 1,\n",
       "         'pixels': 4,\n",
       "         'Bengio': 1,\n",
       "         'dataset': 64,\n",
       "         'With': 1,\n",
       "         'frames': 7,\n",
       "         'space': 2,\n",
       "         'adequate': 1,\n",
       "         'consists': 3,\n",
       "         'Intersection': 1,\n",
       "         'Once': 2,\n",
       "         'segmenting': 2,\n",
       "         'Our': 4,\n",
       "         'Tan': 1,\n",
       "         'gradient': 6,\n",
       "         'parts': 4,\n",
       "         'Denman': 1,\n",
       "         'probabilistically': 1,\n",
       "         'network': 46,\n",
       "         'datasets': 15,\n",
       "         'uniformly': 1,\n",
       "         'corresponding': 5,\n",
       "         'gets': 1,\n",
       "         'parameter': 8,\n",
       "         'world': 1,\n",
       "         'union': 4,\n",
       "         'The': 36,\n",
       "         'entities': 2,\n",
       "         'many': 6,\n",
       "         '1For': 1,\n",
       "         'reason': 2,\n",
       "         'histograms': 1,\n",
       "         'related': 1,\n",
       "         'couple': 1,\n",
       "         'center': 1,\n",
       "         'resizing': 1,\n",
       "         'reduction': 2,\n",
       "         'Snow': 1,\n",
       "         'compromise': 1,\n",
       "         'mechanism': 1,\n",
       "         'age': 1,\n",
       "         'Zoo': 2,\n",
       "         'output': 10,\n",
       "         'uniform': 2,\n",
       "         'For': 14,\n",
       "         'initialize': 1,\n",
       "         'accuracy': 8,\n",
       "         'piece': 1,\n",
       "         'resolution': 6,\n",
       "         'easily': 2,\n",
       "         'DNN': 1,\n",
       "         'follows': 3,\n",
       "         'improve': 2,\n",
       "         'Rodriguez': 3,\n",
       "         'parameters': 5,\n",
       "         '410310Detection': 1,\n",
       "         'Detecting': 2,\n",
       "         'globally': 4,\n",
       "         'Regression': 4,\n",
       "         'noobj': 1,\n",
       "         'Davis': 1,\n",
       "         'Implementation': 1,\n",
       "         'hierarchical': 1,\n",
       "         'Single': 7,\n",
       "         'outputs': 3,\n",
       "         'automatically': 1,\n",
       "         'subsets': 1,\n",
       "         'background': 4,\n",
       "         'localize': 1,\n",
       "         'multicolumn': 4,\n",
       "         'scenes': 9,\n",
       "         'Audibert': 1,\n",
       "         'averaging': 2,\n",
       "         'Resolution': 1,\n",
       "         'Analysis': 7,\n",
       "         'target': 15,\n",
       "         'Cumulative': 2,\n",
       "         'blocks': 2,\n",
       "         'true': 1,\n",
       "         'detector': 3,\n",
       "         'top5': 2,\n",
       "         'data': 28,\n",
       "         'edge': 1,\n",
       "         'varies': 2,\n",
       "         'recoded': 1,\n",
       "         'Siqin': 1,\n",
       "         'individual': 5,\n",
       "         'Systems': 1,\n",
       "         'pushes': 1,\n",
       "         'humans': 4,\n",
       "         'applications': 2,\n",
       "         'often': 1,\n",
       "         'aim': 1,\n",
       "         'environments': 1,\n",
       "         'accurate': 4,\n",
       "         'Convolutional': 11,\n",
       "         'Pascal': 6,\n",
       "         'standard': 1,\n",
       "         'verify': 1,\n",
       "         'tensor': 4,\n",
       "         'maximual': 1,\n",
       "         'protocol': 1,\n",
       "         'predictions': 2,\n",
       "         'count': 22,\n",
       "         'mayi': 1,\n",
       "         'Design': 4,\n",
       "         'give': 1,\n",
       "         'stage': 1,\n",
       "         'resize': 2,\n",
       "         'ground': 22,\n",
       "         'functions': 3,\n",
       "         'introduce': 3,\n",
       "         'Bottou': 1,\n",
       "         'Tota': 1,\n",
       "         'test': 18,\n",
       "         'tracking': 3,\n",
       "         'Multicolumn': 7,\n",
       "         'Symposium': 1,\n",
       "         'speaking': 1,\n",
       "         'Since': 4,\n",
       "         'Zhang': 15,\n",
       "         'four': 2,\n",
       "         'describe': 1,\n",
       "         'WorldExpo10': 4,\n",
       "         'vanishing': 1,\n",
       "         'Comparison': 2,\n",
       "         'massive': 2,\n",
       "         ...})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('image', 93), ('crowd', 92), ('box', 86), ('object', 80), ('density', 71), ('dataset', 64), ('cell', 58), ('YOLO', 54), ('detection', 53), ('layer', 50), ('images', 49), ('grid', 49), ('MCNN', 48), ('bounding', 48), ('network', 46), ('map', 42), ('model', 37), ('The', 36), ('different', 35), ('Part', 34), ('training', 34), ('counting', 33), ('confidence', 31), ('class', 31), ('number', 29), ('error', 29), ('data', 28), ('methods', 25), ('method', 25), ('score', 23)]\n"
     ]
    }
   ],
   "source": [
    "sorted_cnt = sorted(cnt.items(), key=lambda t : t[1],reverse=True)\n",
    "sorted_values = sorted(cnt.values(), reverse=True)\n",
    "sorted_keys = sorted(cnt, key=cnt.get, reverse=True)\n",
    "\n",
    "print(sorted_cnt[:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytagcloud\n",
    "import pandas as pd\n",
    "import webbrowser\n",
    "\n",
    "def generate_cloud(dic, top, save_path):\n",
    "    taglist = pytagcloud.make_tags(dict(dic[:top]).items())\n",
    "    pytagcloud.create_tag_image(taglist, save_path, size=(360, 280), rectangular=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_cloud(sorted_cnt, 50, './cloud.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matplotlib version 3.0.2\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"Matplotlib version\", matplotlib.__version__)\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plontnine version : 0.5.1\n"
     ]
    }
   ],
   "source": [
    "import plotnine\n",
    "from plotnine import *\n",
    "print(\"plontnine version :\",plotnine.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "keyword can't be an expression (<ipython-input-26-290d0a66b113>, line 13)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-26-290d0a66b113>\"\u001b[1;36m, line \u001b[1;32m13\u001b[0m\n\u001b[1;33m    + theme(axis.text.x=element_text(angle=45, hjust=1))\u001b[0m\n\u001b[1;37m           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m keyword can't be an expression\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(sorted_cnt[:30],columns=['word','freq'])\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'word' : sorted_keys[:30] * 2,\n",
    "    'freq' : sorted_values[:30] * 2\n",
    "})\n",
    "\n",
    "\n",
    "(ggplot(df)\n",
    " + geom_col(aes(x='freq',y='word',fill='freq'))\n",
    " + scale_color_hue(l=0.45)                                  # some contrast to make the lines stick out\n",
    " + ggtitle('Greek Letter Analysis')\n",
    " + theme(axis.text.x=element_text(angle=45, hjust=1))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py35",
   "language": "python",
   "name": "py35"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
